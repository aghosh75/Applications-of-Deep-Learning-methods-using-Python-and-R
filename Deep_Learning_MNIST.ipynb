{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset. It has 28 by 28 resolution hand-written images 0 through 9. \n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset int training and testing datasets\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADmxJREFUeJzt3X+IVfeZx/HPo86YZCwZjaP1x+hYCZuIYXVzmYgui0tjSUOJ6R8NlVBcKLWBBlboHxv8p/6zEJZtu4EsTexGakIbW2izESK7TWTBLTTGSTA1XbNqdKKzDs6I5oc/SBN99o85lomZ8z2Te8+95+rzfkG4957nnHsebvzMufd+zz1fc3cBiGdK1Q0AqAbhB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q1LRW7mz27Nne19fXyl0CoQwODurMmTM2mXUbCr+Z3SfpCUlTJf2buz+eWr+vr08DAwON7BJAQq1Wm/S6db/tN7Opkv5V0lclLZO0wcyW1ft8AFqrkc/8/ZKOuvsxd/+TpJ2S1pfTFoBmayT8CySdHPd4KFv2KWa2ycwGzGxgdHS0gd0BKFMj4Z/oS4XP/D7Y3be5e83daz09PQ3sDkCZGgn/kKTecY8XSjrVWDsAWqWR8O+XdLuZLTGzTknflLSrnLYANFvdQ33u/omZPSrpPzU21Lfd3f9YWmcAmqqhcX533y1pd0m9AGghTu8FgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqIZm6TWzQUkfSros6RN3r5XRFMrj7sn6xx9/3ND2RQ4dOlT3tu+++26yvnbt2mR969atubV9+/Yltz137lyyPjg4mKxfunQpWW8HDYU/87fufqaE5wHQQrztB4JqNPwu6bdm9rqZbSqjIQCt0ejb/jXufsrM5kh62czedve941fI/ihskqRFixY1uDsAZWnoyO/up7LbEUkvSOqfYJ1t7l5z91pPT08juwNQorrDb2ZdZvaFq/clfUXSW2U1BqC5GnnbP1fSC2Z29Xl+4e7/UUpXAJqu7vC7+zFJf1liLzes999/P1m/fPlysn7q1Klk/ezZs7m17I9zrpMnTybrFy5cSNaLdHR05NY6Ozsb2vfOnTuT9Zdeeim3tnjx4uS2vb29yfrDDz+crF8PGOoDgiL8QFCEHwiK8ANBEX4gKMIPBFXGr/rCO378eLL+3HPPNfT806dPT9a7u7tza11dXcltp0yp7u9/0TDkmjVrkvWPPvooWX/yySdza/Pnz09uW/S6LVmyJFm/HnDkB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgGOcvQdEVim655ZZk/eLFi2W2U6o5c+Yk60U/yx0dHc2tTZuW/ue3bNmyZB2N4cgPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0Exzl+CGTNmJOv3339/sn706NFkfeHChcn6/v37k/WUmTNnJuvr1q1L1ovG6t97773c2uHDh5Pbork48gNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIXj/Ga2XdLXJI24+/Js2SxJv5TUJ2lQ0kPufq55bV7fin6XvnTp0mS96Lr958+fz62dOHEiue2dd96ZrBeN4xdJzSnQ39/f0HOjMZM58v9M0n3XLHtM0h53v13SnuwxgOtIYfjdfa+ks9csXi9pR3Z/h6QHS+4LQJPV+5l/rrsPS1J2m77WE4C20/Qv/Mxsk5kNmNlA6npuAFqr3vCfNrN5kpTdjuSt6O7b3L3m7rWiC10CaJ16w79L0sbs/kZJL5bTDoBWKQy/mT0v6feS/sLMhszs25Iel7TOzI5IWpc9BnAdKRzEdfcNOaUvl9xLWEXj+EWKrp2fUnQtgb6+vrqfG+2NM/yAoAg/EBThB4Ii/EBQhB8IivADQXHp7htArVbLraV+7itJIyO5J2dKkoaGhpL1osuKo31x5AeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoBjnvwGkLq+9atWq5La7d+9O1vfu3Zusz58/P1mfO3dubq3osuFoLo78QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4/w3uBkzZiTrq1evTtZfeeWVZP3IkSPJ+uDgYG7N3ZPbLl68OFnv6upK1pHGkR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgioc5zez7ZK+JmnE3Zdny7ZK+o6k0Wy1Le6e/mE42lLRdfcfeOCBZP3VV19N1lPzAhw4cCC57fDwcLJ+9913J+vd3d3JenSTOfL/TNJ9Eyz/sbuvyP4j+MB1pjD87r5X0tkW9AKghRr5zP+omf3BzLab2czSOgLQEvWG/yeSlkpaIWlY0g/zVjSzTWY2YGYDo6OjeasBaLG6wu/up939srtfkfRTSf2Jdbe5e83daz09PfX2CaBkdYXfzOaNe/h1SW+V0w6AVpnMUN/zktZKmm1mQ5J+IGmtma2Q5JIGJX23iT0CaILC8Lv7hgkWP9OEXtCGZs2alazfe++9yfrJkydza6+99lpy2zfffDNZP3jwYLK+efPmZD06zvADgiL8QFCEHwiK8ANBEX4gKMIPBMWlu9GQzs7OZH3p0qW5tf379ze078OHDyfr+/bty63dc889De37RsCRHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCYpwfSWfPpq/deuzYsWT93LlzubUrV67U1dNV8+fPT9b7+3MvMAVx5AfCIvxAUIQfCIrwA0ERfiAowg8ERfiBoBjnv8F98MEHyXrRb+LffvvtZP3SpUvJekdHR26t6FoAU6akj0233nprsm5myXp0HPmBoAg/EBThB4Ii/EBQhB8IivADQRF+IKjCcX4z65X0rKQvSroiaZu7P2FmsyT9UlKfpEFJD7l7/o+3UbcLFy4k6++8805u7fjx4w09d9E4fiNuu+22ZL3o2vqpOQFQbDJH/k8kfd/d75S0StL3zGyZpMck7XH32yXtyR4DuE4Uht/dh939jez+h5IOSVogab2kHdlqOyQ92KwmAZTvc33mN7M+SSsl7ZM0192HpbE/EJLmlN0cgOaZdPjNbIakX0va7O7pE8Y/vd0mMxsws4HR0dF6egTQBJMKv5l1aCz4P3f332SLT5vZvKw+T9LIRNu6+zZ3r7l7raenp4yeAZSgMPw29tOoZyQdcvcfjSvtkrQxu79R0ovltwegWSbzk941kr4l6aCZHciWbZH0uKRfmdm3JZ2Q9I3mtHj9O3/+fLJe9HFoz549yfrly5dza11dXclti342W2TOnPRXPStXrsytLVq0qKF9ozGF4Xf330nK+2H0l8ttB0CrcIYfEBThB4Ii/EBQhB8IivADQRF+ICgu3T1JqUtgP/XUU8lti8bSL168mKxPnz49We/u7k7WU4rOuly9enWy3tvbm6xPnTr1c/eE1uDIDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBhRnnf/rpp5P1gYGBZH1oaCi3dvPNNye3veOOO5L1m266KVkvMm1a/v/G5cuXJ7e96667knXG6W9cHPmBoAg/EBThB4Ii/EBQhB8IivADQRF+IKgw4/yPPPJIsr5gwYJkPXV9+r6+vrq3lYrH2js6OpL1VatW5dY6OzuT2yIujvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EFThOL+Z9Up6VtIXJV2RtM3dnzCzrZK+I+nq5PJb3H13sxptlLtX3QLQViZzks8nkr7v7m+Y2RckvW5mL2e1H7v7PzevPQDNUhh+dx+WNJzd/9DMDklKnw4HoO19rs/8ZtYnaaWkfdmiR83sD2a23cxm5myzycwGzGxgdHR0olUAVGDS4TezGZJ+LWmzu38g6SeSlkpaobF3Bj+caDt33+buNXevFc0LB6B1JhV+M+vQWPB/7u6/kSR3P+3ul939iqSfSupvXpsAylYYfjMzSc9IOuTuPxq3fN641b4u6a3y2wPQLJP5tn+NpG9JOmhmB7JlWyRtMLMVklzSoKTvNqVDAE0xmW/7fyfJJii17Zg+gGKc4QcERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwjKWnlJazMblfTuuEWzJZ1pWQOfT7v21q59SfRWrzJ7W+zuk7peXkvD/5mdmw24e62yBhLatbd27Uuit3pV1Rtv+4GgCD8QVNXh31bx/lPatbd27Uuit3pV0luln/kBVKfqIz+AilQSfjO7z8z+18yOmtljVfSQx8wGzeygmR0ws4GKe9luZiNm9ta4ZbPM7GUzO5LdTjhNWkW9bTWz/8teuwNmdn9FvfWa2X+Z2SEz+6OZ/X22vNLXLtFXJa9by9/2m9lUSYclrZM0JGm/pA3u/j8tbSSHmQ1Kqrl75WPCZvY3ks5Letbdl2fL/knSWXd/PPvDOdPd/6FNetsq6XzVMzdnE8rMGz+ztKQHJf2dKnztEn09pApetyqO/P2Sjrr7MXf/k6SdktZX0Efbc/e9ks5es3i9pB3Z/R0a+8fTcjm9tQV3H3b3N7L7H0q6OrN0pa9doq9KVBH+BZJOjns8pPaa8tsl/dbMXjezTVU3M4G52bTpV6dPn1NxP9cqnLm5la6ZWbptXrt6ZrwuWxXhn2j2n3Yacljj7n8l6auSvpe9vcXkTGrm5laZYGbptlDvjNdlqyL8Q5J6xz1eKOlUBX1MyN1PZbcjkl5Q+80+fPrqJKnZ7UjF/fxZO83cPNHM0mqD166dZryuIvz7Jd1uZkvMrFPSNyXtqqCPzzCzruyLGJlZl6SvqP1mH94laWN2f6OkFyvs5VPaZebmvJmlVfFr124zXldykk82lPEvkqZK2u7u/9jyJiZgZl/S2NFeGpvE9BdV9mZmz0taq7FffZ2W9ANJ/y7pV5IWSToh6Rvu3vIv3nJ6W6uxt65/nrn56mfsFvf215L+W9JBSVeyxVs09vm6stcu0dcGVfC6cYYfEBRn+AFBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCOr/AeBa/qb2k8f0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We could also make it black and white.\n",
    "\n",
    "plt.imshow(x_train[0],cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we are goignt o normalize the data. Each \"pixel\" is a feature, and each feature currently ranges from 0 to 255. \n",
    "## So, we normalize to 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00393124 0.02332955 0.02620568 0.02625207 0.17420356 0.17566281\n",
      "  0.28629534 0.05664824 0.51877786 0.71632322 0.77892406 0.89301644\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05780486 0.06524513 0.16128198 0.22713296\n",
      "  0.22277047 0.32790981 0.36833534 0.3689874  0.34978968 0.32678448\n",
      "  0.368094   0.3747499  0.79066747 0.67980478 0.61494005 0.45002403\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12250613 0.45858525 0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.3689874  0.34978968 0.32420121\n",
      "  0.15214552 0.17865984 0.25626376 0.1573102  0.12298801 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04500225 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.28826244 0.26543758 0.34149427 0.31128482\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1541463  0.28272888 0.18358693 0.37314701\n",
      "  0.33153488 0.26569767 0.01601458 0.         0.05945042 0.19891229\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0253731  0.00171577 0.22713296\n",
      "  0.33153488 0.11664776 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.20500962\n",
      "  0.33153488 0.24625638 0.00291174 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.01622378\n",
      "  0.24897876 0.32790981 0.10191096 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04586451 0.31235677 0.32757096 0.23335172 0.14931733 0.00129164\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10498298 0.34940902 0.3689874  0.34978968 0.15370495\n",
      "  0.04089933 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06551419 0.27127137 0.34978968 0.32678448\n",
      "  0.245396   0.05882702 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02333517 0.12857881 0.32549285\n",
      "  0.41390126 0.40743158 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.32161793\n",
      "  0.41390126 0.54251585 0.20001074 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06697006 0.18959827 0.25300993 0.32678448\n",
      "  0.41390126 0.45100715 0.00625034 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05110617 0.19182076 0.33339444 0.3689874  0.34978968 0.32678448\n",
      "  0.40899334 0.39653769 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.04117838 0.16813739\n",
      "  0.28960162 0.32790981 0.36833534 0.3689874  0.34978968 0.25961929\n",
      "  0.12760592 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.04431706 0.11961607 0.36545809 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.28877275 0.111988   0.00258328\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.05298497 0.42752138 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.25273681 0.11646967 0.01312603 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.37491383 0.56222061\n",
      "  0.66525569 0.63253163 0.48748768 0.45852825 0.43408872 0.359873\n",
      "  0.17428513 0.01425695 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.92705966 0.82698729\n",
      "  0.74473314 0.63253163 0.4084877  0.24466922 0.22648107 0.02359823\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we will build the sequential model i.e. we will feed forward. \n",
    "\n",
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0816 10:20:21.758205 13152 deprecation.py:506] From C:\\Users\\Amit Ghosh.SFH-315-0605\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# The imput layer was flat. \n",
    "# So, we need to take this 28x28 image, and make it a flat 1x784. \n",
    "# The first layer is the input layer.\n",
    "# Then we will do the hidden layer -- 2 hidden layers. \n",
    "# We will do a Dense layer. This refers to the fact that it's a densely-connected layer, meaning it's \"fully connected,\" where each node connects to each prior and subsequent node. \n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "# The dense layer will have 128 units\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "# We will another idential layer, the second hidden layer. The activation function is rectified linear.  \n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "\n",
    "#Then we will have our output layer -- the final layer with 10 nodes. \n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2658 - acc: 0.9224\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.1060 - acc: 0.9673\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.0738 - acc: 0.9769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a42c122cc0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the model. Loss is the degree of error\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Then we fit the model\n",
    "model.fit(x_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 35us/sample - loss: 0.0946 - acc: 0.9702\n",
      "0.09462004132922738\n",
      "0.9702\n"
     ]
    }
   ],
   "source": [
    "# This was using the in-sample data. \n",
    "# Now we test on out-of-sample data (data we didn't use to train the model) i.e. the test dataset\n",
    "\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test)  # Evaluate the out of sample data with model\n",
    "print(val_loss)  # Model's loss (error)\n",
    "print(val_acc)  # mModel's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "\n",
    "model.save('epic_num_reader.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0816 10:31:53.462049 13152 deprecation.py:506] From C:\\Users\\Amit Ghosh.SFH-315-0605\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0816 10:31:53.464005 13152 deprecation.py:506] From C:\\Users\\Amit Ghosh.SFH-315-0605\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0816 10:31:53.647513 13152 hdf5_format.py:263] Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "#Reloading the model\n",
    "new_model = tf.keras.models.load_model('epic_num_reader.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0506592e-09 9.5590700e-09 1.2717314e-06 ... 9.9999344e-01\n",
      "  6.8986500e-10 1.5289261e-07]\n",
      " [1.9787447e-07 4.1890815e-02 9.5802599e-01 ... 2.7363819e-07\n",
      "  1.3499601e-06 6.7456720e-09]\n",
      " [3.4926524e-07 9.9993265e-01 4.2094712e-06 ... 1.9986543e-05\n",
      "  2.8350663e-05 4.9229056e-06]\n",
      " ...\n",
      " [2.1574220e-08 1.0160711e-06 1.1894577e-07 ... 9.5638261e-06\n",
      "  5.7375046e-06 2.2952832e-04]\n",
      " [2.5191801e-07 9.9246688e-07 6.2808105e-09 ... 1.1010443e-06\n",
      "  5.5007031e-04 3.6033881e-10]\n",
      " [5.9922762e-08 2.4490582e-08 1.6677816e-09 ... 2.6917396e-12\n",
      "  9.0399466e-09 1.1501504e-10]]\n"
     ]
    }
   ],
   "source": [
    "# Making predictions with the model\n",
    "predictions = new_model.predict(x_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# These are probability distributions. \n",
    "# We can get the actual number by:\n",
    "\n",
    "import numpy as np\n",
    "print(np.argmax(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's look at the input:\n",
    "\n",
    "plt.imshow(x_test[0],cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "\n",
    "# The actual number was indeed 7."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
